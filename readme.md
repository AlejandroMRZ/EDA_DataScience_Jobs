# EDA on Data Science Job Postings

## Dataset

The dataset used in this project is named `data_jobs.csv`. Due to its large size (over 200MB), the file has been compressed into a zip archive named `data_jobs.zip` to make it manageable for version control and storage on GitHub.

### How to Use the Dataset

To run the analysis, you need to decompress the dataset from the zip archive:

1. **Download and Extract**:
   - Locate the file `data_jobs.zip` in the repository.
   - Extract `data_jobs.csv` from the zip archive using any standard decompression tool (e.g., WinRAR, 7-Zip, or built-in OS extraction tools).

2. **Place the Decompressed File**:
   - Ensure that `data_jobs.csv` is in the same directory where the analysis scripts are located so that it can be accessed properly.

### Instructions for Running the EDA

1. **Set Up Environment**:
   - Make sure you have Python installed with the necessary libraries (`pandas`, `matplotlib`, `seaborn`, etc.). You can install all dependencies by running:
     ```bash
     pip install -r requirements.txt
     ```

2. **Run the Analysis**:
   - Once `data_jobs.csv` has been extracted, you can run the Jupyter notebook or Python script to perform the EDA.
   - Open the notebook `Data_Science_jobs_EDA.ipynb` in Jupyter Notebook or JupyterLab and execute the cells sequentially to reproduce the analysis.

### Important Notes

- **File Size Considerations**: The dataset is large, which is why it has been compressed for easier management. Make sure you have enough disk space and memory available for working with the decompressed CSV file.
- **Data Integrity**: Please do not edit the `data_jobs.csv` file unless necessary. Any changes might affect the reproducibility of the analysis.


## Contact
If you encounter any issues or have any questions about the project, feel free to open an issue or reach out.

Happy Analyzing!

